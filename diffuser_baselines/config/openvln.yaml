BASE_TASK_CONFIG_PATH: habitat_extensions/config/vlnce_task.yaml
TRAINER_NAME: openvln_trainer 
SIMULATOR_GPU_IDS: [0]
TORCH_GPU_ID: 0
NUM_ENVIRONMENTS: 1
NUM_PROCESSES: 1
TENSORBOARD_DIR: data/tensorboard_dirs/openvln
CHECKPOINT_FOLDER: data/checkpoints/openvln
EVAL_CKPT_PATH_DIR: data/checkpoints/openvln
RESULTS_DIR: data/checkpoints/openvln/evals
VIDEO_OPTION: []
JobName: openvln
lr_Schedule: False
dagger: True


EVAL:
  USE_CKPT_CONFIG: False
  SPLIT: val_seen # for testing overfitting only
  EPISODE_COUNT: -1
  ACTION_POP: True

IL:
  ckpt_to_load: data/checkpoints/pure_da/ckpt.24.pth
  load_from_ckpt: False # for testing overfitting only 
  epochs: 16
  batch_size: 8
  is_requeue: False # continuo training
  

  RECOLLECT_TRAINER:
    gt_file:
      data/datasets/R2R_VLNCE_v1-3_preprocessed/{split}/{split}_gt.json.gz
    
  DAGGER:
    iterations: 1
    update_size: 6000
    p: 0.75
    preload_lmdb_features: True
    lmdb_features_dir: data/trajectories_dirs/d3ddp_phase2/trajectories.lmdb
    lmdb_commit_frequency: 50
    
    

OPENVLN:
  saving_frequency: 6
  logging_file: data/loggings/train.log
  LR: 2.5e-4
  stage: "align" 
  # stage: training stage in < "align" | "finetune" | "full-finetune" >
  forward_type: "pre-train"
  # forward_type: in < "action_only" | "pre-train"  >

MODEL:
  policy_name: OpenVLNPolicy

TYPE: VLN-CE-v1
SPLIT: joint_train_envdrop
DATA_PATH: data/datasets/R2R_VLNCE_v1-3_preprocessed/{split}/{split}.json.gz
SCENES_DIR: data/scene_datasets/